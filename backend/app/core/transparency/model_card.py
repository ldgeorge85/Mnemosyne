"""
Model Cards Implementation
Based on Google's Model Cards paper and EU AI Act requirements
Track 1: Production-ready transparency documentation
"""

from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union
from pydantic import BaseModel, Field
from enum import Enum
import json
import yaml


class ModelType(str, Enum):
    """Types of AI models"""
    CLASSIFICATION = "classification"
    REGRESSION = "regression"
    CLUSTERING = "clustering"
    GENERATION = "generation"
    EMBEDDING = "embedding"
    RANKING = "ranking"
    EXTRACTION = "extraction"
    OTHER = "other"


class RiskCategory(str, Enum):
    """EU AI Act risk categories"""
    MINIMAL = "minimal"
    LIMITED = "limited"
    HIGH = "high"
    UNACCEPTABLE = "unacceptable"


class PerformanceMetric(BaseModel):
    """Model performance metric"""
    name: str
    value: Union[float, str]
    confidence_interval: Optional[tuple] = None
    slice: Optional[str] = None  # Data slice this metric applies to
    threshold: Optional[float] = None
    description: Optional[str] = None


class DatasetInfo(BaseModel):
    """Information about training/evaluation dataset"""
    name: str
    version: Optional[str] = None
    size: Optional[int] = None
    description: Optional[str] = None
    link: Optional[str] = None
    sensitive_attributes: List[str] = Field(default_factory=list)
    preprocessing: Optional[str] = None


class EthicalConsideration(BaseModel):
    """Ethical considerations for the model"""
    category: str  # e.g., "Bias", "Privacy", "Fairness"
    description: str
    mitigation: Optional[str] = None


class UseCase(BaseModel):
    """Intended or out-of-scope use case"""
    description: str
    examples: List[str] = Field(default_factory=list)


class ModelCard(BaseModel):
    """
    Model Card for AI/ML models
    Implements Google's Model Cards with EU AI Act additions
    """
    
    # Basic Information
    model_name: str
    model_version: str
    model_type: ModelType
    model_description: str
    
    # EU AI Act Compliance
    risk_category: RiskCategory
    eu_ai_act_compliant: bool = Field(default=True)
    conformity_assessment: Optional[str] = None
    
    # Model Details
    developers: List[str] = Field(default_factory=list)
    release_date: Optional[datetime] = None
    license: Optional[str] = None
    citation: Optional[str] = None
    contact: Optional[str] = None
    
    # Intended Use
    primary_intended_uses: List[UseCase] = Field(default_factory=list)
    primary_intended_users: List[str] = Field(default_factory=list)
    out_of_scope_uses: List[UseCase] = Field(default_factory=list)
    
    # Training Data
    training_dataset: Optional[DatasetInfo] = None
    evaluation_dataset: Optional[DatasetInfo] = None
    
    # Model Architecture
    architecture: Optional[str] = None
    model_parameters: Optional[Dict[str, Any]] = None
    input_format: Optional[str] = None
    output_format: Optional[str] = None
    
    # Performance
    performance_metrics: List[PerformanceMetric] = Field(default_factory=list)
    testing_methodology: Optional[str] = None
    
    # Limitations
    technical_limitations: List[str] = Field(default_factory=list)
    performance_limitations: List[str] = Field(default_factory=list)
    
    # Ethical Considerations
    ethical_considerations: List[EthicalConsideration] = Field(default_factory=list)
    fairness_assessment: Optional[str] = None
    bias_analysis: Optional[str] = None
    
    # Transparency
    explainability_method: Optional[str] = None
    interpretability_analysis: Optional[str] = None
    
    # Updates and Maintenance
    update_schedule: Optional[str] = None
    deprecation_date: Optional[datetime] = None
    version_history: List[Dict[str, Any]] = Field(default_factory=list)
    
    # Metadata
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    
    def to_markdown(self) -> str:
        """Export Model Card as Markdown"""
        md = f"# Model Card: {self.model_name} v{self.model_version}\n\n"
        
        # EU AI Act Badge
        risk_badge = {
            RiskCategory.MINIMAL: "ðŸŸ¢ Minimal Risk",
            RiskCategory.LIMITED: "ðŸŸ¡ Limited Risk",
            RiskCategory.HIGH: "ðŸ”´ High Risk",
            RiskCategory.UNACCEPTABLE: "â›” Unacceptable Risk"
        }
        md += f"**EU AI Act Risk Category**: {risk_badge.get(self.risk_category, self.risk_category)}\n\n"
        
        # Model Details
        md += "## Model Details\n\n"
        md += f"- **Type**: {self.model_type.value}\n"
        md += f"- **Description**: {self.model_description}\n"
        if self.developers:
            md += f"- **Developers**: {', '.join(self.developers)}\n"
        if self.release_date:
            md += f"- **Release Date**: {self.release_date.date()}\n"
        if self.license:
            md += f"- **License**: {self.license}\n"
        md += "\n"
        
        # Intended Use
        if self.primary_intended_uses:
            md += "## Intended Use\n\n"
            md += "### Primary Uses\n"
            for use in self.primary_intended_uses:
                md += f"- {use.description}\n"
                for example in use.examples:
                    md += f"  - Example: {example}\n"
            md += "\n"
        
        if self.out_of_scope_uses:
            md += "### Out-of-Scope Uses\n"
            for use in self.out_of_scope_uses:
                md += f"- âš ï¸ {use.description}\n"
            md += "\n"
        
        # Performance
        if self.performance_metrics:
            md += "## Performance\n\n"
            md += "| Metric | Value | Slice | Description |\n"
            md += "|--------|-------|-------|-------------|\n"
            for metric in self.performance_metrics:
                slice_info = metric.slice or "Overall"
                desc = metric.description or "-"
                md += f"| {metric.name} | {metric.value} | {slice_info} | {desc} |\n"
            md += "\n"
        
        # Limitations
        if self.technical_limitations or self.performance_limitations:
            md += "## Limitations\n\n"
            if self.technical_limitations:
                md += "### Technical Limitations\n"
                for limitation in self.technical_limitations:
                    md += f"- {limitation}\n"
                md += "\n"
            if self.performance_limitations:
                md += "### Performance Limitations\n"
                for limitation in self.performance_limitations:
                    md += f"- {limitation}\n"
                md += "\n"
        
        # Ethical Considerations
        if self.ethical_considerations:
            md += "## Ethical Considerations\n\n"
            for consideration in self.ethical_considerations:
                md += f"### {consideration.category}\n"
                md += f"{consideration.description}\n"
                if consideration.mitigation:
                    md += f"**Mitigation**: {consideration.mitigation}\n"
                md += "\n"
        
        # EU AI Act Compliance
        md += "## EU AI Act Compliance\n\n"
        md += f"- **Compliant**: {'âœ… Yes' if self.eu_ai_act_compliant else 'âŒ No'}\n"
        md += f"- **Risk Category**: {self.risk_category.value}\n"
        if self.conformity_assessment:
            md += f"- **Conformity Assessment**: {self.conformity_assessment}\n"
        md += "\n"
        
        md += f"---\n*Generated: {datetime.now(timezone.utc).isoformat()}*\n"
        
        return md
    
    def to_json(self) -> str:
        """Export Model Card as JSON"""
        return self.json(indent=2)
    
    def to_yaml(self) -> str:
        """Export Model Card as YAML"""
        return yaml.dump(self.dict(), default_flow_style=False)


class ModelCardGenerator:
    """Generate Model Cards for different components"""
    
    @staticmethod
    def create_embedding_model_card() -> ModelCard:
        """Create Model Card for text embedding model"""
        return ModelCard(
            model_name="Memory Embedder",
            model_version="1.0.0",
            model_type=ModelType.EMBEDDING,
            model_description="Converts text memories into vector representations for semantic search",
            risk_category=RiskCategory.LIMITED,
            developers=["Mnemosyne Protocol Team"],
            primary_intended_uses=[
                UseCase(
                    description="Convert user memories to searchable vectors",
                    examples=["Personal notes", "Conversations", "Documents"]
                )
            ],
            out_of_scope_uses=[
                UseCase(
                    description="Processing sensitive personal data without consent",
                    examples=["Medical records", "Financial data"]
                )
            ],
            architecture="OpenAI text-embedding-ada-002 or local BERT variant",
            performance_metrics=[
                PerformanceMetric(
                    name="Cosine Similarity",
                    value=0.92,
                    description="Average similarity for related memories"
                ),
                PerformanceMetric(
                    name="Retrieval Accuracy",
                    value=0.88,
                    description="Top-10 retrieval accuracy"
                )
            ],
            technical_limitations=[
                "Maximum input length of 8192 tokens",
                "English language bias in pretrained model",
                "May not capture domain-specific terminology"
            ],
            ethical_considerations=[
                EthicalConsideration(
                    category="Privacy",
                    description="Embeddings may encode personal information",
                    mitigation="Embeddings stored encrypted, never shared without consent"
                ),
                EthicalConsideration(
                    category="Bias",
                    description="Language model may have cultural biases",
                    mitigation="Users can choose alternative embedding models"
                )
            ]
        )
    
    @staticmethod
    def create_agent_model_card(agent_name: str) -> ModelCard:
        """Create Model Card for an AI agent"""
        return ModelCard(
            model_name=f"{agent_name} Agent",
            model_version="1.0.0",
            model_type=ModelType.GENERATION,
            model_description=f"LLM-based agent for {agent_name.lower()} analysis and reflection",
            risk_category=RiskCategory.LIMITED,
            developers=["Mnemosyne Protocol Team"],
            primary_intended_uses=[
                UseCase(
                    description="Analyze and reflect on user memories",
                    examples=["Provide insights", "Identify patterns", "Suggest connections"]
                )
            ],
            out_of_scope_uses=[
                UseCase(
                    description="Medical or psychological diagnosis",
                    examples=["Mental health assessment", "Medical advice"]
                ),
                UseCase(
                    description="Legal or financial advice",
                    examples=["Investment recommendations", "Legal counsel"]
                )
            ],
            architecture="GPT-4/Claude or local Llama variant with custom prompting",
            performance_metrics=[
                PerformanceMetric(
                    name="Relevance Score",
                    value=0.85,
                    description="Human-rated relevance of reflections"
                ),
                PerformanceMetric(
                    name="Coherence",
                    value=0.91,
                    description="Logical consistency of outputs"
                )
            ],
            technical_limitations=[
                "Context window limitations",
                "May hallucinate connections",
                "Dependent on memory quality"
            ],
            ethical_considerations=[
                EthicalConsideration(
                    category="Agency",
                    description="Agent suggestions should not override user judgment",
                    mitigation="Clearly labeled as AI suggestions, not directives"
                ),
                EthicalConsideration(
                    category="Transparency",
                    description="Users should understand AI involvement",
                    mitigation="Model card available, AI clearly identified"
                )
            ]
        )
    
    @staticmethod
    def create_classification_model_card() -> ModelCard:
        """Create Model Card for memory importance classifier"""
        return ModelCard(
            model_name="Memory Importance Scorer",
            model_version="1.0.0",
            model_type=ModelType.CLASSIFICATION,
            model_description="Scores memory importance for prioritization and retrieval",
            risk_category=RiskCategory.MINIMAL,
            developers=["Mnemosyne Protocol Team"],
            primary_intended_uses=[
                UseCase(
                    description="Score memory importance for retrieval ranking",
                    examples=["Prioritize recent memories", "Identify key events"]
                )
            ],
            architecture="Gradient boosting with temporal and semantic features",
            performance_metrics=[
                PerformanceMetric(
                    name="AUROC",
                    value=0.82,
                    description="Area under ROC curve for importance prediction"
                ),
                PerformanceMetric(
                    name="Precision@10",
                    value=0.75,
                    description="Precision in top 10 results"
                )
            ],
            technical_limitations=[
                "Requires sufficient memory history",
                "May be biased toward recent events"
            ],
            ethical_considerations=[
                EthicalConsideration(
                    category="Fairness",
                    description="May prioritize certain types of content",
                    mitigation="User can adjust importance weights"
                )
            ]
        )


# Service layer for Model Cards
class ModelCardService:
    """Service for managing Model Cards"""
    
    def __init__(self):
        self.generator = ModelCardGenerator()
        self.cards: Dict[str, ModelCard] = {}
        self._initialize_cards()
    
    def _initialize_cards(self):
        """Initialize standard model cards"""
        self.cards["memory_embedder"] = self.generator.create_embedding_model_card()
        self.cards["memory_scorer"] = self.generator.create_classification_model_card()
        
        # Create cards for standard agents
        for agent in ["Engineer", "Philosopher", "Psychologist"]:
            self.cards[f"agent_{agent.lower()}"] = self.generator.create_agent_model_card(agent)
    
    async def get_model_card(self, model_id: str) -> Optional[ModelCard]:
        """Get a model card by ID"""
        return self.cards.get(model_id)
    
    async def list_model_cards(self) -> List[Dict[str, Any]]:
        """List all available model cards"""
        return [
            {
                "id": model_id,
                "name": card.model_name,
                "version": card.model_version,
                "type": card.model_type.value,
                "risk_category": card.risk_category.value
            }
            for model_id, card in self.cards.items()
        ]
    
    async def export_model_card(
        self,
        model_id: str,
        format: str = "markdown"
    ) -> Optional[str]:
        """Export a model card in specified format"""
        card = self.cards.get(model_id)
        if not card:
            return None
        
        if format == "markdown":
            return card.to_markdown()
        elif format == "json":
            return card.to_json()
        elif format == "yaml":
            return card.to_yaml()
        
        return None
    
    async def validate_eu_compliance(self, model_id: str) -> Dict[str, Any]:
        """Validate EU AI Act compliance for a model"""
        card = self.cards.get(model_id)
        if not card:
            return {"compliant": False, "error": "Model card not found"}
        
        issues = []
        
        # Check required fields for EU AI Act
        if not card.model_description:
            issues.append("Missing model description")
        if not card.primary_intended_uses:
            issues.append("Missing intended uses")
        if not card.technical_limitations:
            issues.append("Missing technical limitations")
        if not card.ethical_considerations:
            issues.append("Missing ethical considerations")
        
        # High-risk systems need additional documentation
        if card.risk_category == RiskCategory.HIGH:
            if not card.conformity_assessment:
                issues.append("High-risk system missing conformity assessment")
            if not card.fairness_assessment:
                issues.append("High-risk system missing fairness assessment")
        
        return {
            "compliant": len(issues) == 0,
            "risk_category": card.risk_category.value,
            "issues": issues
        }